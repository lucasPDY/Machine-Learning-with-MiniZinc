{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combining Machine Learning and Optimization \n",
    "## With Gurobi and sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning topics \n",
    "Touching the elephant here, but ~~not there~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Supervised Learning\n",
    "  * Algorithm selection and hyper-parametric optimization\n",
    "  * KFold assessment vs overfitting\n",
    "  * Separating training from prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "~~Unsupervised Learning~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "~~Time Series Data~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "~~Deep Learning~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization topics\n",
    "\n",
    "  * Exploratory programming to application deployment\n",
    "  * Coping with the combinatorial explosion\n",
    "  * Validating optimization with simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# All Under the Banner of Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Soda Promotion Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have the challenge of designing the upcoming promotion campaign for a Soda Company. The intended objective is to bolster sales while at the same time obeying various business constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The First Challenge\n",
    "\n",
    "We need to predict impact of different price points on the expected sales for each type of soda.\n",
    "\n",
    "To do this, we need to train a soda sales predictor from a historical data table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examine historical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Cost Per Unit</th>\n",
       "      <th>Easter Included</th>\n",
       "      <th>Super Bowl Included</th>\n",
       "      <th>Christmas Included</th>\n",
       "      <th>Other Holiday</th>\n",
       "      <th>4 Wk Avg Temp</th>\n",
       "      <th>4 Wk Avg Humidity</th>\n",
       "      <th>Sales M-1 weeks</th>\n",
       "      <th>Sales M-2 weeks</th>\n",
       "      <th>Sales M-3 weeks</th>\n",
       "      <th>Sales M-4 Weeks</th>\n",
       "      <th>Sales M-5 weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alpine Stream</td>\n",
       "      <td>135.7</td>\n",
       "      <td>2.0775</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>80.94</td>\n",
       "      <td>69.33</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bright</td>\n",
       "      <td>3054.8</td>\n",
       "      <td>1.3425</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>80.94</td>\n",
       "      <td>69.33</td>\n",
       "      <td>473.4</td>\n",
       "      <td>301.8</td>\n",
       "      <td>188.8</td>\n",
       "      <td>101.4</td>\n",
       "      <td>81.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Crisp Clear</td>\n",
       "      <td>50.3</td>\n",
       "      <td>1.6000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>80.94</td>\n",
       "      <td>69.33</td>\n",
       "      <td>42.2</td>\n",
       "      <td>73.8</td>\n",
       "      <td>69.4</td>\n",
       "      <td>72.8</td>\n",
       "      <td>75.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Popsi Kola</td>\n",
       "      <td>347.9</td>\n",
       "      <td>1.7650</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>80.94</td>\n",
       "      <td>69.33</td>\n",
       "      <td>22.9</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.6</td>\n",
       "      <td>22.1</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DC Kola</td>\n",
       "      <td>979.3</td>\n",
       "      <td>1.9250</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>80.94</td>\n",
       "      <td>69.33</td>\n",
       "      <td>45.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>35.5</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Koala Kola</td>\n",
       "      <td>1173.3</td>\n",
       "      <td>2.6725</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>80.94</td>\n",
       "      <td>69.33</td>\n",
       "      <td>248.2</td>\n",
       "      <td>344.6</td>\n",
       "      <td>305.3</td>\n",
       "      <td>263.2</td>\n",
       "      <td>290.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AB Root Beer</td>\n",
       "      <td>592.4</td>\n",
       "      <td>3.8625</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>80.94</td>\n",
       "      <td>69.33</td>\n",
       "      <td>79.7</td>\n",
       "      <td>74.8</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mr. Popper</td>\n",
       "      <td>31.3</td>\n",
       "      <td>2.9750</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>80.94</td>\n",
       "      <td>69.33</td>\n",
       "      <td>5.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11 Down</td>\n",
       "      <td>242.7</td>\n",
       "      <td>1.5300</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>81.24</td>\n",
       "      <td>68.78</td>\n",
       "      <td>22.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Alpine Stream</td>\n",
       "      <td>220.1</td>\n",
       "      <td>1.9100</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>81.24</td>\n",
       "      <td>68.78</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bright</td>\n",
       "      <td>3208.6</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>81.24</td>\n",
       "      <td>68.78</td>\n",
       "      <td>954.6</td>\n",
       "      <td>473.4</td>\n",
       "      <td>301.8</td>\n",
       "      <td>188.8</td>\n",
       "      <td>101.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Crisp Clear</td>\n",
       "      <td>48.3</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>81.24</td>\n",
       "      <td>68.78</td>\n",
       "      <td>44.4</td>\n",
       "      <td>42.2</td>\n",
       "      <td>73.8</td>\n",
       "      <td>69.4</td>\n",
       "      <td>72.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Popsi Kola</td>\n",
       "      <td>498.9</td>\n",
       "      <td>1.6500</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>81.24</td>\n",
       "      <td>68.78</td>\n",
       "      <td>19.7</td>\n",
       "      <td>22.9</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.6</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DC Kola</td>\n",
       "      <td>1399.6</td>\n",
       "      <td>1.8700</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>81.24</td>\n",
       "      <td>68.78</td>\n",
       "      <td>86.8</td>\n",
       "      <td>45.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Koala Kola</td>\n",
       "      <td>1418.4</td>\n",
       "      <td>2.6350</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>81.24</td>\n",
       "      <td>68.78</td>\n",
       "      <td>665.1</td>\n",
       "      <td>248.2</td>\n",
       "      <td>344.6</td>\n",
       "      <td>305.3</td>\n",
       "      <td>263.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AB Root Beer</td>\n",
       "      <td>517.7</td>\n",
       "      <td>3.8475</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>81.24</td>\n",
       "      <td>68.78</td>\n",
       "      <td>93.2</td>\n",
       "      <td>79.7</td>\n",
       "      <td>74.8</td>\n",
       "      <td>55.8</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mr. Popper</td>\n",
       "      <td>31.6</td>\n",
       "      <td>2.9650</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>81.24</td>\n",
       "      <td>68.78</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11 Down</td>\n",
       "      <td>393.9</td>\n",
       "      <td>1.4200</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.17</td>\n",
       "      <td>69.89</td>\n",
       "      <td>29.3</td>\n",
       "      <td>22.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Alpine Stream</td>\n",
       "      <td>284.4</td>\n",
       "      <td>1.7975</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.17</td>\n",
       "      <td>69.89</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bright</td>\n",
       "      <td>4202.2</td>\n",
       "      <td>1.3100</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.17</td>\n",
       "      <td>69.89</td>\n",
       "      <td>685.8</td>\n",
       "      <td>954.6</td>\n",
       "      <td>473.4</td>\n",
       "      <td>301.8</td>\n",
       "      <td>188.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Crisp Clear</td>\n",
       "      <td>42.1</td>\n",
       "      <td>1.5375</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.17</td>\n",
       "      <td>69.89</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44.4</td>\n",
       "      <td>42.2</td>\n",
       "      <td>73.8</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Popsi Kola</td>\n",
       "      <td>660.5</td>\n",
       "      <td>1.5650</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.17</td>\n",
       "      <td>69.89</td>\n",
       "      <td>24.1</td>\n",
       "      <td>19.7</td>\n",
       "      <td>22.9</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DC Kola</td>\n",
       "      <td>2243.9</td>\n",
       "      <td>1.8325</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.17</td>\n",
       "      <td>69.89</td>\n",
       "      <td>113.1</td>\n",
       "      <td>86.8</td>\n",
       "      <td>45.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>37.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Koala Kola</td>\n",
       "      <td>1853.5</td>\n",
       "      <td>2.5900</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.17</td>\n",
       "      <td>69.89</td>\n",
       "      <td>289.4</td>\n",
       "      <td>665.1</td>\n",
       "      <td>248.2</td>\n",
       "      <td>344.6</td>\n",
       "      <td>305.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AB Root Beer</td>\n",
       "      <td>480.4</td>\n",
       "      <td>3.8425</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.17</td>\n",
       "      <td>69.89</td>\n",
       "      <td>132.4</td>\n",
       "      <td>93.2</td>\n",
       "      <td>79.7</td>\n",
       "      <td>74.8</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mr. Popper</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.9550</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.17</td>\n",
       "      <td>69.89</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>11 Down</td>\n",
       "      <td>401.5</td>\n",
       "      <td>1.4150</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.88</td>\n",
       "      <td>71.08</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.3</td>\n",
       "      <td>22.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Alpine Stream</td>\n",
       "      <td>281.0</td>\n",
       "      <td>1.8650</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.88</td>\n",
       "      <td>71.08</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bright</td>\n",
       "      <td>4910.4</td>\n",
       "      <td>1.2775</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.88</td>\n",
       "      <td>71.08</td>\n",
       "      <td>851.0</td>\n",
       "      <td>685.8</td>\n",
       "      <td>954.6</td>\n",
       "      <td>473.4</td>\n",
       "      <td>301.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Crisp Clear</td>\n",
       "      <td>33.9</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.88</td>\n",
       "      <td>71.08</td>\n",
       "      <td>50.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44.4</td>\n",
       "      <td>42.2</td>\n",
       "      <td>73.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>Crisp Clear</td>\n",
       "      <td>567.8</td>\n",
       "      <td>1.2325</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>77.69</td>\n",
       "      <td>71.22</td>\n",
       "      <td>51.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>92.3</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>Crisp Clear</td>\n",
       "      <td>579.5</td>\n",
       "      <td>1.2625</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>78.23</td>\n",
       "      <td>70.75</td>\n",
       "      <td>229.8</td>\n",
       "      <td>51.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>92.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Crisp Clear</td>\n",
       "      <td>641.8</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>78.76</td>\n",
       "      <td>69.73</td>\n",
       "      <td>213.3</td>\n",
       "      <td>229.8</td>\n",
       "      <td>51.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>34.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>Crisp Clear</td>\n",
       "      <td>617.1</td>\n",
       "      <td>1.3600</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>79.39</td>\n",
       "      <td>69.07</td>\n",
       "      <td>229.6</td>\n",
       "      <td>213.3</td>\n",
       "      <td>229.8</td>\n",
       "      <td>51.3</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Alpine Stream</td>\n",
       "      <td>131.7</td>\n",
       "      <td>2.1375</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.79</td>\n",
       "      <td>71.12</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>Alpine Stream</td>\n",
       "      <td>84.8</td>\n",
       "      <td>2.2275</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.00</td>\n",
       "      <td>70.51</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>Alpine Stream</td>\n",
       "      <td>73.2</td>\n",
       "      <td>2.2925</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.20</td>\n",
       "      <td>69.83</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>Alpine Stream</td>\n",
       "      <td>131.7</td>\n",
       "      <td>2.1375</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.79</td>\n",
       "      <td>71.12</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>Alpine Stream</td>\n",
       "      <td>84.8</td>\n",
       "      <td>2.2275</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.00</td>\n",
       "      <td>70.51</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>Alpine Stream</td>\n",
       "      <td>73.2</td>\n",
       "      <td>2.2925</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.20</td>\n",
       "      <td>69.83</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>Crisp Clear</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.4700</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.79</td>\n",
       "      <td>71.12</td>\n",
       "      <td>33.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>50.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Crisp Clear</td>\n",
       "      <td>40.7</td>\n",
       "      <td>1.4275</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.00</td>\n",
       "      <td>70.51</td>\n",
       "      <td>27.7</td>\n",
       "      <td>33.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>50.7</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>Crisp Clear</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.4700</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.79</td>\n",
       "      <td>71.12</td>\n",
       "      <td>33.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>50.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>Crisp Clear</td>\n",
       "      <td>40.7</td>\n",
       "      <td>1.4275</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.00</td>\n",
       "      <td>70.51</td>\n",
       "      <td>27.7</td>\n",
       "      <td>33.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>50.7</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>11 Down</td>\n",
       "      <td>266.7</td>\n",
       "      <td>1.4550</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.79</td>\n",
       "      <td>71.12</td>\n",
       "      <td>30.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.3</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>11 Down</td>\n",
       "      <td>266.7</td>\n",
       "      <td>1.4550</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.79</td>\n",
       "      <td>71.12</td>\n",
       "      <td>30.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.3</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>Alpine Stream</td>\n",
       "      <td>371.7</td>\n",
       "      <td>1.9975</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.52</td>\n",
       "      <td>68.21</td>\n",
       "      <td>36.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>Alpine Stream</td>\n",
       "      <td>371.7</td>\n",
       "      <td>1.9975</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.52</td>\n",
       "      <td>68.21</td>\n",
       "      <td>36.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Bright</td>\n",
       "      <td>4024.0</td>\n",
       "      <td>1.2725</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.79</td>\n",
       "      <td>71.12</td>\n",
       "      <td>1022.4</td>\n",
       "      <td>887.8</td>\n",
       "      <td>851.0</td>\n",
       "      <td>685.8</td>\n",
       "      <td>954.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Bright</td>\n",
       "      <td>2703.0</td>\n",
       "      <td>1.2825</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.00</td>\n",
       "      <td>70.51</td>\n",
       "      <td>1263.6</td>\n",
       "      <td>1022.4</td>\n",
       "      <td>887.8</td>\n",
       "      <td>851.0</td>\n",
       "      <td>685.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Bright</td>\n",
       "      <td>4024.0</td>\n",
       "      <td>1.2725</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.79</td>\n",
       "      <td>71.12</td>\n",
       "      <td>1022.4</td>\n",
       "      <td>887.8</td>\n",
       "      <td>851.0</td>\n",
       "      <td>685.8</td>\n",
       "      <td>954.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Bright</td>\n",
       "      <td>2703.0</td>\n",
       "      <td>1.2825</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.00</td>\n",
       "      <td>70.51</td>\n",
       "      <td>1263.6</td>\n",
       "      <td>1022.4</td>\n",
       "      <td>887.8</td>\n",
       "      <td>851.0</td>\n",
       "      <td>685.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Popsi Kola</td>\n",
       "      <td>343.5</td>\n",
       "      <td>1.6725</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.79</td>\n",
       "      <td>71.12</td>\n",
       "      <td>43.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>24.1</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Popsi Kola</td>\n",
       "      <td>343.5</td>\n",
       "      <td>1.6725</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.79</td>\n",
       "      <td>71.12</td>\n",
       "      <td>43.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>24.1</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Mr. Popper</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2.8950</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.79</td>\n",
       "      <td>71.12</td>\n",
       "      <td>16.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Mr. Popper</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2.9000</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.00</td>\n",
       "      <td>70.51</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Mr. Popper</td>\n",
       "      <td>32.6</td>\n",
       "      <td>2.8475</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.52</td>\n",
       "      <td>68.21</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Mr. Popper</td>\n",
       "      <td>38.4</td>\n",
       "      <td>2.8950</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>80.79</td>\n",
       "      <td>71.12</td>\n",
       "      <td>16.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Mr. Popper</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2.9000</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.00</td>\n",
       "      <td>70.51</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Mr. Popper</td>\n",
       "      <td>32.6</td>\n",
       "      <td>2.8475</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>81.52</td>\n",
       "      <td>68.21</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Product   Sales  Cost Per Unit Easter Included Super Bowl Included  \\\n",
       "10   Alpine Stream   135.7         2.0775              No                  No   \n",
       "11          Bright  3054.8         1.3425              No                  No   \n",
       "12     Crisp Clear    50.3         1.6000              No                  No   \n",
       "13      Popsi Kola   347.9         1.7650              No                  No   \n",
       "14         DC Kola   979.3         1.9250              No                  No   \n",
       "15      Koala Kola  1173.3         2.6725              No                  No   \n",
       "16    AB Root Beer   592.4         3.8625              No                  No   \n",
       "17      Mr. Popper    31.3         2.9750              No                  No   \n",
       "18         11 Down   242.7         1.5300              No                  No   \n",
       "19   Alpine Stream   220.1         1.9100              No                  No   \n",
       "20          Bright  3208.6         1.3325              No                  No   \n",
       "21     Crisp Clear    48.3         1.5500              No                  No   \n",
       "22      Popsi Kola   498.9         1.6500              No                  No   \n",
       "23         DC Kola  1399.6         1.8700              No                  No   \n",
       "24      Koala Kola  1418.4         2.6350              No                  No   \n",
       "25    AB Root Beer   517.7         3.8475              No                  No   \n",
       "26      Mr. Popper    31.6         2.9650              No                  No   \n",
       "27         11 Down   393.9         1.4200              No                  No   \n",
       "28   Alpine Stream   284.4         1.7975              No                  No   \n",
       "29          Bright  4202.2         1.3100              No                  No   \n",
       "30     Crisp Clear    42.1         1.5375              No                  No   \n",
       "31      Popsi Kola   660.5         1.5650              No                  No   \n",
       "32         DC Kola  2243.9         1.8325              No                  No   \n",
       "33      Koala Kola  1853.5         2.5900              No                  No   \n",
       "34    AB Root Beer   480.4         3.8425              No                  No   \n",
       "35      Mr. Popper    37.0         2.9550              No                  No   \n",
       "36         11 Down   401.5         1.4150              No                  No   \n",
       "37   Alpine Stream   281.0         1.8650              No                  No   \n",
       "38          Bright  4910.4         1.2775              No                  No   \n",
       "39     Crisp Clear    33.9         1.5500              No                  No   \n",
       "..             ...     ...            ...             ...                 ...   \n",
       "566    Crisp Clear   567.8         1.2325              No                  No   \n",
       "567    Crisp Clear   579.5         1.2625              No                  No   \n",
       "568    Crisp Clear   641.8         1.3000              No                  No   \n",
       "569    Crisp Clear   617.1         1.3600              No                  No   \n",
       "570  Alpine Stream   131.7         2.1375              No                 Yes   \n",
       "571  Alpine Stream    84.8         2.2275              No                 Yes   \n",
       "572  Alpine Stream    73.2         2.2925              No                 Yes   \n",
       "573  Alpine Stream   131.7         2.1375              No                 Yes   \n",
       "574  Alpine Stream    84.8         2.2275              No                 Yes   \n",
       "575  Alpine Stream    73.2         2.2925              No                 Yes   \n",
       "576    Crisp Clear    42.0         1.4700              No                 Yes   \n",
       "577    Crisp Clear    40.7         1.4275              No                 Yes   \n",
       "578    Crisp Clear    42.0         1.4700              No                 Yes   \n",
       "579    Crisp Clear    40.7         1.4275              No                 Yes   \n",
       "580        11 Down   266.7         1.4550              No                 Yes   \n",
       "581        11 Down   266.7         1.4550              No                 Yes   \n",
       "582  Alpine Stream   371.7         1.9975              No                 Yes   \n",
       "583  Alpine Stream   371.7         1.9975              No                 Yes   \n",
       "584         Bright  4024.0         1.2725              No                 Yes   \n",
       "585         Bright  2703.0         1.2825              No                 Yes   \n",
       "586         Bright  4024.0         1.2725              No                 Yes   \n",
       "587         Bright  2703.0         1.2825              No                 Yes   \n",
       "588     Popsi Kola   343.5         1.6725              No                 Yes   \n",
       "589     Popsi Kola   343.5         1.6725              No                 Yes   \n",
       "590     Mr. Popper    38.4         2.8950              No                 Yes   \n",
       "591     Mr. Popper    32.5         2.9000              No                 Yes   \n",
       "592     Mr. Popper    32.6         2.8475              No                 Yes   \n",
       "593     Mr. Popper    38.4         2.8950              No                 Yes   \n",
       "594     Mr. Popper    32.5         2.9000              No                 Yes   \n",
       "595     Mr. Popper    32.6         2.8475              No                 Yes   \n",
       "\n",
       "    Christmas Included Other Holiday  4 Wk Avg Temp  4 Wk Avg Humidity  \\\n",
       "10                 Yes            No          80.94              69.33   \n",
       "11                 Yes            No          80.94              69.33   \n",
       "12                 Yes            No          80.94              69.33   \n",
       "13                 Yes            No          80.94              69.33   \n",
       "14                 Yes            No          80.94              69.33   \n",
       "15                 Yes            No          80.94              69.33   \n",
       "16                 Yes            No          80.94              69.33   \n",
       "17                 Yes            No          80.94              69.33   \n",
       "18                 Yes            No          81.24              68.78   \n",
       "19                 Yes            No          81.24              68.78   \n",
       "20                 Yes            No          81.24              68.78   \n",
       "21                 Yes            No          81.24              68.78   \n",
       "22                 Yes            No          81.24              68.78   \n",
       "23                 Yes            No          81.24              68.78   \n",
       "24                 Yes            No          81.24              68.78   \n",
       "25                 Yes            No          81.24              68.78   \n",
       "26                 Yes            No          81.24              68.78   \n",
       "27                  No            No          81.17              69.89   \n",
       "28                  No            No          81.17              69.89   \n",
       "29                  No            No          81.17              69.89   \n",
       "30                  No            No          81.17              69.89   \n",
       "31                  No            No          81.17              69.89   \n",
       "32                  No            No          81.17              69.89   \n",
       "33                  No            No          81.17              69.89   \n",
       "34                  No            No          81.17              69.89   \n",
       "35                  No            No          81.17              69.89   \n",
       "36                  No            No          80.88              71.08   \n",
       "37                  No            No          80.88              71.08   \n",
       "38                  No            No          80.88              71.08   \n",
       "39                  No            No          80.88              71.08   \n",
       "..                 ...           ...            ...                ...   \n",
       "566                 No            No          77.69              71.22   \n",
       "567                 No            No          78.23              70.75   \n",
       "568                 No            No          78.76              69.73   \n",
       "569                 No            No          79.39              69.07   \n",
       "570                 No            No          80.79              71.12   \n",
       "571                 No            No          81.00              70.51   \n",
       "572                 No            No          81.20              69.83   \n",
       "573                 No            No          80.79              71.12   \n",
       "574                 No            No          81.00              70.51   \n",
       "575                 No            No          81.20              69.83   \n",
       "576                 No            No          80.79              71.12   \n",
       "577                 No            No          81.00              70.51   \n",
       "578                 No            No          80.79              71.12   \n",
       "579                 No            No          81.00              70.51   \n",
       "580                 No            No          80.79              71.12   \n",
       "581                 No            No          80.79              71.12   \n",
       "582                 No            No          81.52              68.21   \n",
       "583                 No            No          81.52              68.21   \n",
       "584                 No            No          80.79              71.12   \n",
       "585                 No            No          81.00              70.51   \n",
       "586                 No            No          80.79              71.12   \n",
       "587                 No            No          81.00              70.51   \n",
       "588                 No            No          80.79              71.12   \n",
       "589                 No            No          80.79              71.12   \n",
       "590                 No            No          80.79              71.12   \n",
       "591                 No            No          81.00              70.51   \n",
       "592                 No            No          81.52              68.21   \n",
       "593                 No            No          80.79              71.12   \n",
       "594                 No            No          81.00              70.51   \n",
       "595                 No            No          81.52              68.21   \n",
       "\n",
       "     Sales M-1 weeks  Sales M-2 weeks  Sales M-3 weeks  Sales M-4 Weeks  \\\n",
       "10               1.9              2.4              2.2              2.0   \n",
       "11             473.4            301.8            188.8            101.4   \n",
       "12              42.2             73.8             69.4             72.8   \n",
       "13              22.9             23.1             22.6             22.1   \n",
       "14              45.5             56.0             37.7             35.5   \n",
       "15             248.2            344.6            305.3            263.2   \n",
       "16              79.7             74.8             55.8             19.0   \n",
       "17               5.4              7.1              6.4              6.8   \n",
       "18              22.4             10.6             17.0             22.4   \n",
       "19               2.1              1.9              2.4              2.2   \n",
       "20             954.6            473.4            301.8            188.8   \n",
       "21              44.4             42.2             73.8             69.4   \n",
       "22              19.7             22.9             23.1             22.6   \n",
       "23              86.8             45.5             56.0             37.7   \n",
       "24             665.1            248.2            344.6            305.3   \n",
       "25              93.2             79.7             74.8             55.8   \n",
       "26               6.6              5.4              7.1              6.4   \n",
       "27              29.3             22.4             10.6             17.0   \n",
       "28               4.0              2.1              1.9              2.4   \n",
       "29             685.8            954.6            473.4            301.8   \n",
       "30              46.0             44.4             42.2             73.8   \n",
       "31              24.1             19.7             22.9             23.1   \n",
       "32             113.1             86.8             45.5             56.0   \n",
       "33             289.4            665.1            248.2            344.6   \n",
       "34             132.4             93.2             79.7             74.8   \n",
       "35               5.7              6.6              5.4              7.1   \n",
       "36               6.7             29.3             22.4             10.6   \n",
       "37               3.7              4.0              2.1              1.9   \n",
       "38             851.0            685.8            954.6            473.4   \n",
       "39              50.7             46.0             44.4             42.2   \n",
       "..               ...              ...              ...              ...   \n",
       "566             51.3             32.0             34.2             92.3   \n",
       "567            229.8             51.3             32.0             34.2   \n",
       "568            213.3            229.8             51.3             32.0   \n",
       "569            229.6            213.3            229.8             51.3   \n",
       "570             10.2              4.9              3.7              4.0   \n",
       "571              8.2             10.2              4.9              3.7   \n",
       "572              3.9              8.2             10.2              4.9   \n",
       "573             10.2              4.9              3.7              4.0   \n",
       "574              8.2             10.2              4.9              3.7   \n",
       "575              3.9              8.2             10.2              4.9   \n",
       "576             33.2             31.5             50.7             46.0   \n",
       "577             27.7             33.2             31.5             50.7   \n",
       "578             33.2             31.5             50.7             46.0   \n",
       "579             27.7             33.2             31.5             50.7   \n",
       "580             30.6              9.5              6.7             29.3   \n",
       "581             30.6              9.5              6.7             29.3   \n",
       "582             36.8              6.9              3.9              8.2   \n",
       "583             36.8              6.9              3.9              8.2   \n",
       "584           1022.4            887.8            851.0            685.8   \n",
       "585           1263.6           1022.4            887.8            851.0   \n",
       "586           1022.4            887.8            851.0            685.8   \n",
       "587           1263.6           1022.4            887.8            851.0   \n",
       "588             43.8             34.0             22.6             24.1   \n",
       "589             43.8             34.0             22.6             24.1   \n",
       "590             16.6              7.4              5.2              5.7   \n",
       "591             18.0             16.6              7.4              5.2   \n",
       "592              7.6              7.4              7.9             18.0   \n",
       "593             16.6              7.4              5.2              5.7   \n",
       "594             18.0             16.6              7.4              5.2   \n",
       "595              7.6              7.4              7.9             18.0   \n",
       "\n",
       "     Sales M-5 weeks  \n",
       "10               1.4  \n",
       "11              81.6  \n",
       "12              75.4  \n",
       "13              19.9  \n",
       "14              21.9  \n",
       "15             290.3  \n",
       "16              18.3  \n",
       "17               7.4  \n",
       "18              13.5  \n",
       "19               2.0  \n",
       "20             101.4  \n",
       "21              72.8  \n",
       "22              22.1  \n",
       "23              35.5  \n",
       "24             263.2  \n",
       "25              19.0  \n",
       "26               6.8  \n",
       "27              22.4  \n",
       "28               2.2  \n",
       "29             188.8  \n",
       "30              69.4  \n",
       "31              22.6  \n",
       "32              37.7  \n",
       "33             305.3  \n",
       "34              55.8  \n",
       "35               6.4  \n",
       "36              17.0  \n",
       "37               2.4  \n",
       "38             301.8  \n",
       "39              73.8  \n",
       "..               ...  \n",
       "566             66.5  \n",
       "567             92.3  \n",
       "568             34.2  \n",
       "569             32.0  \n",
       "570              2.1  \n",
       "571              4.0  \n",
       "572              3.7  \n",
       "573              2.1  \n",
       "574              4.0  \n",
       "575              3.7  \n",
       "576             44.4  \n",
       "577             46.0  \n",
       "578             44.4  \n",
       "579             46.0  \n",
       "580             22.4  \n",
       "581             22.4  \n",
       "582             10.2  \n",
       "583             10.2  \n",
       "584            954.6  \n",
       "585            685.8  \n",
       "586            954.6  \n",
       "587            685.8  \n",
       "588             19.7  \n",
       "589             19.7  \n",
       "590              6.6  \n",
       "591              5.7  \n",
       "592             16.6  \n",
       "593              6.6  \n",
       "594              5.7  \n",
       "595             16.6  \n",
       "\n",
       "[586 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "df_hist = pandas.read_excel(\"soda_sales_historical_data.xlsx\")\n",
    "df_hist[10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_hist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert categorical columns to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>Cost Per Unit</th>\n",
       "      <th>4 Wk Avg Temp</th>\n",
       "      <th>4 Wk Avg Humidity</th>\n",
       "      <th>Sales M-1 weeks</th>\n",
       "      <th>Sales M-2 weeks</th>\n",
       "      <th>Sales M-3 weeks</th>\n",
       "      <th>Sales M-4 Weeks</th>\n",
       "      <th>Sales M-5 weeks</th>\n",
       "      <th>dmy_Product_11 Down</th>\n",
       "      <th>...</th>\n",
       "      <th>dmy_Product_Koala Kola</th>\n",
       "      <th>dmy_Product_Mr. Popper</th>\n",
       "      <th>dmy_Product_Popsi Kola</th>\n",
       "      <th>dmy_Easter Included_No</th>\n",
       "      <th>dmy_Easter Included_Yes</th>\n",
       "      <th>dmy_Super Bowl Included_No</th>\n",
       "      <th>dmy_Super Bowl Included_Yes</th>\n",
       "      <th>dmy_Christmas Included_No</th>\n",
       "      <th>dmy_Christmas Included_Yes</th>\n",
       "      <th>dmy_Other Holiday_No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.9</td>\n",
       "      <td>1.6625</td>\n",
       "      <td>80.69</td>\n",
       "      <td>69.19</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.8</td>\n",
       "      <td>2.2725</td>\n",
       "      <td>80.69</td>\n",
       "      <td>69.19</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3385.6</td>\n",
       "      <td>1.3475</td>\n",
       "      <td>80.69</td>\n",
       "      <td>69.19</td>\n",
       "      <td>301.8</td>\n",
       "      <td>188.8</td>\n",
       "      <td>101.4</td>\n",
       "      <td>81.6</td>\n",
       "      <td>213.8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.5</td>\n",
       "      <td>1.6600</td>\n",
       "      <td>80.69</td>\n",
       "      <td>69.19</td>\n",
       "      <td>73.8</td>\n",
       "      <td>69.4</td>\n",
       "      <td>72.8</td>\n",
       "      <td>75.4</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181.1</td>\n",
       "      <td>1.8725</td>\n",
       "      <td>80.69</td>\n",
       "      <td>69.19</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.6</td>\n",
       "      <td>22.1</td>\n",
       "      <td>19.9</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sales  Cost Per Unit  4 Wk Avg Temp  4 Wk Avg Humidity  Sales M-1 weeks  \\\n",
       "0    51.9         1.6625          80.69              69.19             17.0   \n",
       "1    55.8         2.2725          80.69              69.19              2.4   \n",
       "2  3385.6         1.3475          80.69              69.19            301.8   \n",
       "3    63.5         1.6600          80.69              69.19             73.8   \n",
       "4   181.1         1.8725          80.69              69.19             23.1   \n",
       "\n",
       "   Sales M-2 weeks  Sales M-3 weeks  Sales M-4 Weeks  Sales M-5 weeks  \\\n",
       "0             22.4             13.5             14.5             28.0   \n",
       "1              2.2              2.0              1.4              0.5   \n",
       "2            188.8            101.4             81.6            213.8   \n",
       "3             69.4             72.8             75.4             57.4   \n",
       "4             22.6             22.1             19.9             23.2   \n",
       "\n",
       "   dmy_Product_11 Down  ...  dmy_Product_Koala Kola  dmy_Product_Mr. Popper  \\\n",
       "0                    1  ...                       0                       0   \n",
       "1                    0  ...                       0                       0   \n",
       "2                    0  ...                       0                       0   \n",
       "3                    0  ...                       0                       0   \n",
       "4                    0  ...                       0                       0   \n",
       "\n",
       "   dmy_Product_Popsi Kola  dmy_Easter Included_No  dmy_Easter Included_Yes  \\\n",
       "0                       0                       1                        0   \n",
       "1                       0                       1                        0   \n",
       "2                       0                       1                        0   \n",
       "3                       0                       1                        0   \n",
       "4                       1                       1                        0   \n",
       "\n",
       "   dmy_Super Bowl Included_No  dmy_Super Bowl Included_Yes  \\\n",
       "0                           1                            0   \n",
       "1                           1                            0   \n",
       "2                           1                            0   \n",
       "3                           1                            0   \n",
       "4                           1                            0   \n",
       "\n",
       "   dmy_Christmas Included_No  dmy_Christmas Included_Yes  dmy_Other Holiday_No  \n",
       "0                          0                           1                     1  \n",
       "1                          0                           1                     1  \n",
       "2                          0                           1                     1  \n",
       "3                          0                           1                     1  \n",
       "4                          0                           1                     1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame, get_dummies\n",
    "categorical_columns = ['Product','Easter Included','Super Bowl Included', \n",
    "                       'Christmas Included', 'Other Holiday']\n",
    "df_hist = get_dummies(df_hist, prefix={k:\"dmy_%s\"%k for k in categorical_columns},\n",
    "                      columns = list(categorical_columns))\n",
    "df_hist[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Picking the right predictor algorithm is of upmost importance\n",
    "\n",
    "Hence we examine our choices here in great deal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.ensemble import BaggingRegressor\n",
    "# from sklearn import model_selection\n",
    "# experiments = {\"Algorithm\":[\"Ordinary Least Squares\", \"Regression Tree\", \n",
    "#                             \"Big Random Forest\", \"Random Forest\", \n",
    "#                             \"Bagging\"], \n",
    "#                \"Objects\" : [lambda : LinearRegression(), \n",
    "#                             lambda : DecisionTreeRegressor(), \n",
    "#                             lambda : RandomForestRegressor(n_estimators=100), \n",
    "#                             lambda : RandomForestRegressor(), \n",
    "#                             lambda : BaggingRegressor()], \n",
    "#                \"Predictions\":[[] for _ in range(5)]}\n",
    "# actuals = []\n",
    "\n",
    "from torch import *\n",
    "import torch.nn as nn\n",
    "\n",
    "len(df_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resist the temptation to overfit!\n",
    "Instead, split the samples into train, test subsections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "torch.Size([596, 1])\n",
      "torch.Size([596, 24])\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# [_.shape for _ in  train_test_split(df_hist.drop(\"Sales\", axis=1), \n",
    "#                                     df_hist[\"Sales\"], test_size=0.25)]\n",
    "import torch.utils.data\n",
    "trainSize = int(0.75 * len(df_hist))\n",
    "testSize = len(df_hist) - trainSize\n",
    "target = df_hist[\"Sales\"]\n",
    "dropped = df_hist.drop(\"Sales\", axis=1)\n",
    "# trainDataSet, testDataSet = torch.utils.data.random_split(dropped, [trainSize, testSize])\n",
    "# print(type(df_hist))\n",
    "# targetCols = ['Sales']\n",
    "# trainingCols = []\n",
    "# for columnHeaders in df_hist.columns:\n",
    "#     if columnHeaders != 'Sales':\n",
    "#         trainingCols.append(columnHeaders)\n",
    "# print(targetCols)\n",
    "# print(trainingCols)\n",
    "print(type(target))\n",
    "targetTensor = torch.tensor(target.values).float()\n",
    "targetTensor = targetTensor.resize_((596,1))\n",
    "print(targetTensor.shape)\n",
    "trainingTensor = torch.tensor(dropped.values).float()\n",
    "print(trainingTensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### By repeatedly splitting, training, and testing, you can create a realistic simulation of prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.6625,  80.6900,  69.1900,  17.0000,  22.4000,  13.5000,  14.5000,\n",
       "           28.0000,   1.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   1.0000,   0.0000,   1.0000,   0.0000,\n",
       "            0.0000,   1.0000,   1.0000],\n",
       "         [  2.2725,  80.6900,  69.1900,   2.4000,   2.2000,   2.0000,   1.4000,\n",
       "            0.5000,   0.0000,   0.0000,   1.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   1.0000,   0.0000,   1.0000,   0.0000,\n",
       "            0.0000,   1.0000,   1.0000],\n",
       "         [  1.3475,  80.6900,  69.1900, 301.8000, 188.8000, 101.4000,  81.6000,\n",
       "          213.8000,   0.0000,   0.0000,   0.0000,   1.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   1.0000,   0.0000,   1.0000,   0.0000,\n",
       "            0.0000,   1.0000,   1.0000]]), tensor([[  51.9000],\n",
       "         [  55.8000],\n",
       "         [3385.6001]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for _ in range (4):\n",
    "#     train_X, test_X, train_y, test_y = (\n",
    "#         train_test_split(df_hist.drop(\"Sales\", axis=1), \n",
    "#                          df_hist[\"Sales\"], test_size=0.25))\n",
    "#     for i, obj_factory in enumerate(experiments[\"Objects\"]):\n",
    "#         obj = obj_factory()\n",
    "#         obj.fit(y=train_y,X=train_X)\n",
    "#         experiments[\"Predictions\"][i] += list(obj.predict(test_X))\n",
    "#     actuals += list(test_y)\n",
    "# actuals = pandas.Series(actuals)\n",
    "# experiments[\"Predictions\"] = list(map(pandas.Series, experiments[\"Predictions\"]))\n",
    "# # trainDataSet\n",
    "from torch.utils.data import *\n",
    "# Define dataset\n",
    "train_ds = TensorDataset(trainingTensor, targetTensor)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 2.7150, 80.2000, 68.0100, 67.7000, 68.0000, 81.7000, 64.7000, 79.1000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "           0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "         [ 4.1025, 80.2000, 68.0100, 11.6000, 15.2000, 18.6000,  8.4000, 10.1000,\n",
       "           0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "         [ 2.8925, 81.5900, 67.5900,  7.4000,  7.9000, 18.0000, 16.6000,  7.4000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  1.0000,  0.0000,  1.0000],\n",
       "         [ 1.6000, 76.0300, 68.4300,  4.3000, 34.1000,  6.0000,  7.3000, 15.6000,\n",
       "           1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "         [ 1.7925, 76.0300, 68.4300, 16.9000, 18.4000, 20.9000, 27.0000, 31.8000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000]]),\n",
       " tensor([[729.4000],\n",
       "         [312.6000],\n",
       "         [ 28.8000],\n",
       "         [ 69.0000],\n",
       "         [170.5000]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1083,  0.1404, -0.0648,  0.1107, -0.1041,  0.1893,  0.1841, -0.2018,\n",
      "          0.1767, -0.1248,  0.0291, -0.1982, -0.0098, -0.1594,  0.1781,  0.0496,\n",
      "         -0.1231, -0.0706, -0.1572,  0.1575, -0.1679,  0.0292, -0.0371,  0.0064]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1165], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "\n",
    "model = nn.Linear(24, 1)  # 24 inputs, 1 output\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "# using stochastic gradient descent (SGD) as the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nn.functional\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_fn = F.mse_loss\n",
    "# mean squared error as the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([596, 24])\n",
      "torch.Size([596, 1])\n",
      "tensor(756662.9375, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(model(trainingTensor), targetTensor)\n",
    "print(trainingTensor.float().shape)\n",
    "print(targetTensor.float().shape)\n",
    "print(loss)\n",
    "# print(targetTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    for epoch in range(num_epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            # Generate predictions\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            # Perform gradient descent\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    print('Training loss: ', loss_fn(model(trainingTensor), targetTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  tensor(756662.9375, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Train the model for 100 epochs\n",
    "fit(100, model, loss_fn, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.8624)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(trainingTensor)\n",
    "preds[1][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(55.8000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with targets\n",
    "targetTensor[1][0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_superbowl_original = pandas.read_excel(\"super_bowl_promotion_data.xlsx\")\n",
    "df_superbowl = get_dummies(df_superbowl_original, \n",
    "                           prefix={k:\"dmy_%s\"%k for k in categorical_columns},\n",
    "                           columns = list(categorical_columns))\n",
    "assert \"Sales\" not in df_superbowl.columns \n",
    "assert {\"Sales\"}.union(df_superbowl.columns).issubset(set(df_hist.columns))\n",
    "len(df_superbowl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the current data table might have less categorical range than the historical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for fld in set(df_hist.columns).difference(df_superbowl.columns, {\"Sales\"}):\n",
    "    assert fld.startswith(\"dmy_\")\n",
    "    df_superbowl[fld] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Take care!!** `sklearn` [has no concept of columns](https://github.com/scikit-learn/scikit-learn/issues/7242). We make sure that the `df_superbowl` columns are ordered consistently with the `df_hist` independent column sub-matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3425e+00, 8.0790e+01, 7.1120e+01, 2.1525e+01, 2.2075e+01, 3.0125e+01,\n",
       "         3.9400e+01, 3.8775e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.7125e+00, 8.0790e+01, 7.1120e+01, 4.8775e+01, 3.8025e+01, 3.1025e+01,\n",
       "         3.1300e+01, 2.7550e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.9975e+00, 8.0790e+01, 7.1120e+01, 1.5525e+01, 6.4750e+00, 5.1750e+00,\n",
       "         6.5250e+00, 5.3000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [2.5650e+00, 8.0790e+01, 7.1120e+01, 3.6915e+02, 4.1667e+02, 3.5260e+02,\n",
       "         3.7535e+02, 4.4223e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.2900e+00, 8.0790e+01, 7.1120e+01, 1.0205e+03, 1.0579e+03, 9.2040e+02,\n",
       "         8.0820e+02, 8.3047e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.5375e+00, 8.0790e+01, 7.1120e+01, 1.8925e+01, 1.4175e+01, 1.4550e+01,\n",
       "         1.3825e+01, 2.2250e+01, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [2.5350e+00, 8.0790e+01, 7.1120e+01, 3.6915e+02, 4.1667e+02, 3.5260e+02,\n",
       "         3.7535e+02, 4.4223e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [2.1500e+00, 8.0790e+01, 7.1120e+01, 1.5525e+01, 6.4750e+00, 5.1750e+00,\n",
       "         6.5250e+00, 5.3000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.9325e+00, 8.0790e+01, 7.1120e+01, 2.3007e+02, 2.5312e+02, 2.1125e+02,\n",
       "         1.9090e+02, 1.5168e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.2825e+00, 8.0790e+01, 7.1120e+01, 1.0205e+03, 1.0579e+03, 9.2040e+02,\n",
       "         8.0820e+02, 8.3047e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [3.7300e+00, 8.0790e+01, 7.1120e+01, 1.6282e+02, 1.4185e+02, 1.6675e+02,\n",
       "         1.4165e+02, 1.4470e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.5125e+00, 8.0790e+01, 7.1120e+01, 1.8925e+01, 1.4175e+01, 1.4550e+01,\n",
       "         1.3825e+01, 2.2250e+01, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [2.1375e+00, 8.0790e+01, 7.1120e+01, 1.5525e+01, 6.4750e+00, 5.1750e+00,\n",
       "         6.5250e+00, 5.3000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [2.8475e+00, 8.0790e+01, 7.1120e+01, 1.1500e+01, 1.1460e+01, 1.1020e+01,\n",
       "         1.0580e+01, 8.3000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.7500e+00, 8.0790e+01, 7.1120e+01, 4.8775e+01, 3.8025e+01, 3.1025e+01,\n",
       "         3.1300e+01, 2.7550e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.4275e+00, 8.0790e+01, 7.1120e+01, 2.1525e+01, 2.2075e+01, 3.0125e+01,\n",
       "         3.9400e+01, 3.8775e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.7275e+00, 8.0790e+01, 7.1120e+01, 4.8775e+01, 3.8025e+01, 3.1025e+01,\n",
       "         3.1300e+01, 2.7550e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [2.9850e+00, 8.0790e+01, 7.1120e+01, 1.1500e+01, 1.1460e+01, 1.1020e+01,\n",
       "         1.0580e+01, 8.3000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [2.4825e+00, 8.0790e+01, 7.1120e+01, 3.6915e+02, 4.1667e+02, 3.5260e+02,\n",
       "         3.7535e+02, 4.4223e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.2725e+00, 8.0790e+01, 7.1120e+01, 1.0205e+03, 1.0579e+03, 9.2040e+02,\n",
       "         8.0820e+02, 8.3047e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [2.9000e+00, 8.0790e+01, 7.1120e+01, 1.1500e+01, 1.1460e+01, 1.1020e+01,\n",
       "         1.0580e+01, 8.3000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [2.5600e+00, 8.0790e+01, 7.1120e+01, 3.6915e+02, 4.1667e+02, 3.5260e+02,\n",
       "         3.7535e+02, 4.4223e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [3.7700e+00, 8.0790e+01, 7.1120e+01, 1.6282e+02, 1.4185e+02, 1.6675e+02,\n",
       "         1.4165e+02, 1.4470e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.3125e+00, 8.0790e+01, 7.1120e+01, 2.1525e+01, 2.2075e+01, 3.0125e+01,\n",
       "         3.9400e+01, 3.8775e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.9250e+00, 8.0790e+01, 7.1120e+01, 2.3007e+02, 2.5312e+02, 2.1125e+02,\n",
       "         1.9090e+02, 1.5168e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.4700e+00, 8.0790e+01, 7.1120e+01, 2.1525e+01, 2.2075e+01, 3.0125e+01,\n",
       "         3.9400e+01, 3.8775e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.5600e+00, 8.0790e+01, 7.1120e+01, 1.8925e+01, 1.4175e+01, 1.4550e+01,\n",
       "         1.3825e+01, 2.2250e+01, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [2.8950e+00, 8.0790e+01, 7.1120e+01, 1.1500e+01, 1.1460e+01, 1.1020e+01,\n",
       "         1.0580e+01, 8.3000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.6725e+00, 8.0790e+01, 7.1120e+01, 4.8775e+01, 3.8025e+01, 3.1025e+01,\n",
       "         3.1300e+01, 2.7550e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.8900e+00, 8.0790e+01, 7.1120e+01, 2.3007e+02, 2.5312e+02, 2.1125e+02,\n",
       "         1.9090e+02, 1.5168e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [3.8425e+00, 8.0790e+01, 7.1120e+01, 1.6282e+02, 1.4185e+02, 1.6675e+02,\n",
       "         1.4165e+02, 1.4470e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.4550e+00, 8.0790e+01, 7.1120e+01, 1.8925e+01, 1.4175e+01, 1.4550e+01,\n",
       "         1.3825e+01, 2.2250e+01, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [1.9150e+00, 8.0790e+01, 7.1120e+01, 2.3007e+02, 2.5312e+02, 2.1125e+02,\n",
       "         1.9090e+02, 1.5168e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [2.2275e+00, 8.0790e+01, 7.1120e+01, 1.5525e+01, 6.4750e+00, 5.1750e+00,\n",
       "         6.5250e+00, 5.3000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [2.8925e+00, 8.0790e+01, 7.1120e+01, 1.1500e+01, 1.1460e+01, 1.1020e+01,\n",
       "         1.0580e+01, 8.3000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "        [3.8125e+00, 8.0790e+01, 7.1120e+01, 1.6282e+02, 1.4185e+02, 1.6675e+02,\n",
       "         1.4165e+02, 1.4470e+02, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_superbowl = df_superbowl[list(df_hist.drop(\"Sales\", axis=1).columns)]\n",
    "# print(df_superbowl)\n",
    "testingTensor = torch.tensor(df_superbowl.values).float()\n",
    "testingTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 12.0020],\n",
       "        [ 14.2297],\n",
       "        [  9.0473],\n",
       "        [ 51.2663],\n",
       "        [165.0101],\n",
       "        [  8.4197],\n",
       "        [ 51.2630],\n",
       "        [  9.0638],\n",
       "        [ 50.3742],\n",
       "        [165.0093],\n",
       "        [ 38.6505],\n",
       "        [  8.4169],\n",
       "        [  9.0625],\n",
       "        [  9.4434],\n",
       "        [ 14.2337],\n",
       "        [ 12.0112],\n",
       "        [ 14.2313],\n",
       "        [  9.4583],\n",
       "        [ 51.2574],\n",
       "        [165.0082],\n",
       "        [  9.4491],\n",
       "        [ 51.2658],\n",
       "        [ 38.6548],\n",
       "        [ 11.9987],\n",
       "        [ 50.3734],\n",
       "        [ 12.0158],\n",
       "        [  8.4221],\n",
       "        [  9.4486],\n",
       "        [ 14.2253],\n",
       "        [ 50.3696],\n",
       "        [ 38.6627],\n",
       "        [  8.4107],\n",
       "        [ 50.3723],\n",
       "        [  9.0722],\n",
       "        [  9.4483],\n",
       "        [ 38.6594]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model(testingTensor)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prediction in hand, we commence optimization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LaTeX summary of family of equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\max & sales\\\\\n",
    "s.t. & X_{b,p}\\in\\{0,1\\}\\quad\\forall (b,p)\\in Prod\\\\\n",
    "     & \\sum\\left(X_{b,p}:{(b,p)\\in Prod} \\right)=1\\quad\\forall b\\in Soda\\\\\n",
    "     & \\sum\\left(X_{b,p}:{(b,p)\\in Prod, p\\neq p_o, T(b)=t} \\right) \\leq max_t\\quad\\forall t\\\\\n",
    "     & sales = \\sum\\left(f_{b,p} X_{b,p}:{(b,p)\\in Prod}\\right)\\\\\n",
    "     & revenue = \\sum\\left(f_{b,p}  p X_{b,p}:{(b,p)\\in Prod} \\right)\\\\\n",
    "     & investment = \\sum\\left(\\left(f_{b,p} - f_{b,p_o}\\right)_+ p_o X_{b,p}:{(b,p)\\in Prod} \\right)\\\\\n",
    "     & investment <= max_{investment}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Putting the optimization input set together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-6f8a373dc09b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mforecast_sales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_superbowl_original\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Product\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Cost Per Unit\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mforecast_sales\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Sales\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mforecast_sales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Product'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Cost Per Unit'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3369\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3370\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3445\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3446\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3633\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_convert_platform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3634\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3635\u001b[1;33m                     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3636\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3637\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36masarray_tuplesafe\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconstruct_1d_object_array_from_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "forecast_sales = df_superbowl_original[[\"Product\", \"Cost Per Unit\"]].copy()\n",
    "forecast_sales[\"Sales\"] = predicted\n",
    "forecast_sales.set_index(['Product','Cost Per Unit'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soda_family = {'11 Down': 'Clear', 'AB Root Beer': 'Dark', \n",
    "               'Alpine Stream': 'Clear', 'Bright': 'Clear', \n",
    "               'Crisp Clear': 'Clear', 'DC Kola': 'Dark',\n",
    "               'Koala Kola': 'Dark', 'Mr. Popper': 'Dark', \n",
    "               'Popsi Kola': 'Dark'}\n",
    "family  = set(soda_family[j] for j in soda_family)\n",
    "soda    = set(j for j in soda_family)\n",
    "max_prom = {f:2 for f in family}\n",
    "max_investment = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "product_prices = set(forecast_sales.index.values)\n",
    "normal_price = {b:0 for b in soda}\n",
    "for b,p in product_prices:\n",
    "    normal_price[b] = max(normal_price[b],p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that not all estimated discounts yield a boost in sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "meaningful_discounts = 0\n",
    "for b,p in product_prices:\n",
    "    if forecast_sales.Sales[b,p] > forecast_sales.Sales[b,normal_price[b]]:\n",
    "        meaningful_discounts += 1\n",
    "meaningful_discounts, len(forecast_sales) - len(soda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building a MIP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\begin{array}{l}\n",
    "X_{b,p}\\in\\{0,1\\}\\quad\\forall (b,p)\\in Prod\\\\\n",
    "0 \\leq sales\\\\\n",
    "0 \\leq revenue\\\\\n",
    "0 \\leq investment \\leq max_{investment}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import gurobipy as gu\n",
    "model = gu.Model()\n",
    "select_price = model.addVars(product_prices,vtype=gu.GRB.BINARY,name='X')\n",
    "sales        = model.addVar(name='sales')\n",
    "revenue      = model.addVar(name='revenue')\n",
    "investment   = model.addVar(ub=max_investment, name='investment')\n",
    "gusum = gu.quicksum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \n",
    "sales = \\sum\\left(f_{b,p} X_{b,p}:{(b,p)\\in Prod}\\right)\\\\\n",
    "revenue = \\sum\\left(f_{b,p} p X_{b,p}:{(b,p)\\in Prod} \\right)\\\\\n",
    "investment = \\sum\\left(\\left(f_{b,p} - f_{b,p_o}\\right)_+ p_o X_{b,p}:{(b,p)\\in Prod} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.addConstr(sales == select_price.prod(forecast_sales.Sales), name='sales')\n",
    "model.addConstr(revenue == gusum(forecast_sales.Sales[b,p] * p * \n",
    "                                 select_price[b,p] for b,p in product_prices), \n",
    "                name='revenue')\n",
    "model.addConstr(investment == \n",
    "                gusum(max(0,forecast_sales.Sales[b,p] - \n",
    "                            forecast_sales.Sales[b,normal_price[b]]) *\n",
    "                        normal_price[b] * select_price[b,p] \n",
    "                        for b,p in product_prices),\n",
    "                name='investment')\n",
    "model.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\sum\\left(X_{b,p}:{(b,p)\\in Prod} \\right)=1\\quad\\forall b\\in Soda\\\\\n",
    "\\sum\\left(X_{b,p}:{(b,p)\\in Prod, p\\neq p_o, T(b)=t} \\right) \\leq max_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.addConstrs((select_price.sum(b,'*') == 1 for b in soda), name='OnePrice')\n",
    "model.addConstrs((gusum(select_price[b,p] for b,p in product_prices if \n",
    "                        soda_family[b] == f and p != normal_price[b] ) \n",
    "                  <= max_prom[f] for f in family),\n",
    "                 name='MaxProm')\n",
    "model.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimize and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.setObjective(sales, sense=gu.GRB.MAXIMIZE)\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.status == gu.GRB.OPTIMAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Only the paranoid survive\n",
    "Carefully sanity check the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sales.X, revenue.X, investment.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "price_selections = {\"Product\":[], \"Price\":[], \"Is Discount\":[], \"Family\":[]}\n",
    "for b, p in product_prices:\n",
    "    if abs(select_price[b,p].X -1) < 0.0001: # i.e. almost one\n",
    "        price_selections[\"Product\"].append(b)\n",
    "        price_selections[\"Price\"].append(p)\n",
    "        price_selections[\"Is Discount\"].append(p < normal_price[b])\n",
    "        price_selections[\"Family\"].append(soda_family[b])\n",
    "(DataFrame(price_selections).set_index(\"Product\")\n",
    " [[\"Price\", \"Is Discount\", \"Family\"]].sort_values(\"Family\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Create a range of predictions to simulate the behavior of our solution under a range of conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "simulated_KPI = {'Sales':[],'Revenue':[],'Investment':[]}\n",
    "Z = select_price\n",
    "num_infeas = 0\n",
    "for i in range(100):\n",
    "    np.random.seed(i)\n",
    "    fitted = RandomForestRegressor(n_estimators=100,\n",
    "                                   n_jobs=4).fit(y=df_hist[\"Sales\"],\n",
    "                                                 X=df_hist.drop(\"Sales\", axis=1))\n",
    "    forecast = df_superbowl_original[['Product', 'Cost Per Unit']].copy()\n",
    "    forecast[\"Sales\"] = fitted.predict(df_superbowl)\n",
    "    forecast = forecast.set_index(['Product','Cost Per Unit'])\n",
    "    sales, revenue, investment = 0, 0, 0\n",
    "    for b,p in product_prices:\n",
    "        sales   += forecast.Sales[b,p] * Z[b,p].X\n",
    "        revenue += forecast.Sales[b,p] * p * Z[b,p].X\n",
    "        investment += (max(0,forecast.Sales[b,p] - \n",
    "                             forecast.Sales[b,normal_price[b]]) * \n",
    "                       normal_price[b] * Z[b,p].X)\n",
    "    if investment > max_investment:\n",
    "        num_infeas += 1\n",
    "    simulated_KPI['Sales'].append(sales)\n",
    "    simulated_KPI['Revenue'].append(revenue)\n",
    "    simulated_KPI['Investment'].append(investment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = {'Sales','Revenue','Investment'}\n",
    "color=iter(cm.rainbow(np.linspace(0,1,3)))\n",
    "for t in data:\n",
    "    plt.figure(figsize=(7,4),dpi=300)\n",
    "    plt.hist(simulated_KPI[t],50,normed=1,color=next(color), alpha=0.75)\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel(t)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_infeas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank you for joining us\n",
    " * If you haven't already done so, please register at http://www.gurobi.com/ and then visit http://www.gurobi.com/downloads/get-anaconda to try Gurobi and Python for yourself.\n",
    " * Explore ticdat at https://pypi.python.org/pypi/ticdat/ and see the Opalytics Cloud Platform in action at http://bit.ly/2sjEuZt. \n",
    " * For questions about Gurobi Pricing contact sales@gurobi.com or sales@gurobi.de.\n",
    " * A recording of the webinar, including the slides, will be available in roughly one week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some extra references for Stochastic, Robust, and Risk optimization\n",
    "\n",
    "After the webinar we received a lot of requests for further material on this topic. The following list is an (incomplete) list of sources for these topics, but a good starting point for it.\n",
    "\n",
    "## Books\n",
    "\n",
    "<ul>\n",
    "    <li>Stochastic Programming, Peter Kall, Stein W. Walace, 1994</li>\n",
    "    <li>Optimization Methods in Finance, Gerard Cornuejols and Reha T&uuml;t&uuml;nc&uuml;, 2006</li>\n",
    "    <li>Lectures on Stochastic Programming: Modeling and Theory, Alexander Shapiro, Darinka Dentcheva, Andrzej Ruszczy&nacute;ski, 2009</li>\n",
    "    <li>Robust Optimization, Aharon Ben-Tal, Laurent El Ghaoui, Arkadi Nemirovski, 2009</li>\n",
    "    <li>Introduction to Stochastic Programming, John Birge, Fran&ccedil;ois Louveaux, 2011</li>\n",
    "    <li>Modeling with Stochastic Programming, Alan J. King, Stein W. Walace, 2012</li>\n",
    "</ul>\n",
    "\n",
    "## Some papers\n",
    "\n",
    "<ul>\n",
    "    <li>Optimization of Conditional Value-at-Risk, R. Tyrrell Rockafellar, Stanislav Uryasev, 2000</li>\n",
    "    <li>Supplier-Retailer Flexible Commitments Contracts: A Robust Optimization Approach, Aharon Ben Tal , Boaz Golany, Arcadi Nemirovskiy, Jean-Philippe Vial, 2003</li>\n",
    "    <li>Tractable Approximations to Robust Conic Optimization Problems,Dimitris Bertsimas, Melvyn Sim, 2006</li>\n",
    "    <li>Modeling and optimization of risk, Pavlo Krokhmal, Michael Zabarankin,Stan Uryasev, 2011</li>\n",
    "</ul>\n",
    "\n",
    "## Other resources\n",
    "\n",
    "The stochastic optimization society in their <a href=\"www.stoprog.org\">web site</a> has several tutorials and further links.\n",
    "\n",
    "### Special Thanks\n",
    "\n",
    "I would like to specially thank (in alphabetic order) to\n",
    "<a href=\"http://www2.isye.gatech.edu/people/faculty/Shabbir_Ahmed/\">Shabbir Ahmed</a>, Georgia Tech, \n",
    "<a href=\"http://www.uai.cl/academicos/cuerpo-academico/tito-homem-de-mello\">Tito Homem-de-mello</a>, Universidad Adolfo Iba&ntilde;ez, \n",
    "<a href=\"https://directory.engr.wisc.edu/ie/faculty/luedtke_james\">Jim Luedtke</a>, University of Wisconsin-Madison,\n",
    "<a href=\"http://www.mccormick.northwestern.edu/research-faculty/directory/profiles/morton-david.html\">David Morton</a>,  Northwestern University, and\n",
    "<a href=\"http://bernardokp.uai.cl/\">Bernardo Pagnoncelli</a>, Universidad Adolfo Iba&ntilde;ez, for suggesting books, links and papers. Any omission or error is my fault.\n",
    "\n",
    "Daniel Espinoza,<br>\n",
    "Senior Developer,<br>\n",
    "Gurobi Optimization Inc.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
